# app_gradio.py
from __future__ import annotations
import asyncio
from pathlib import Path
from urllib.parse import quote
from typing import List, Tuple

import gradio as gr
from gradio import mount_gradio_app
from fastapi import FastAPI, Query
from fastapi.responses import JSONResponse, FileResponse

from parser import sniff_serial
from downloader import download_video
from extractor import extract_frames
from state_store import PAGE_TO_PATH
from utils import detect_platform, extract_code, find_existing_by_code
from config import STEP_MIN, STEP_MAX

# ç¤ºä¾‹ï¼ˆæœ‰ç”¨æˆ·è¾“å…¥æ—¶è‡ªåŠ¨å¿½ç•¥ï¼‰
EXAMPLES = [
    "https://v.douyin.com/nZasikV8ea4/",
    "https://v.douyin.com/urI4O20_90U/",
]

RUNNING = False  # ç®€å•äº’æ–¥
Row = List[str]  # [page_url, direct_url, status]


# ---------- å·¥å…· ----------
def precheck_rows(urls: List[str]) -> Tuple[List[Row], List[str]]:
    """
    ç«‹åˆ»ç”Ÿæˆæ¸…å•ï¼šå·²ä¸‹è½½ -> ç›´æ¥æ ‡æ³¨ï¼›æœªä¸‹è½½ -> å¾…è§£æ
    è¿”å› rows ä¸éœ€è¦è§£æçš„ to_parse
    """
    rows, to_parse = [], []
    for u in urls:
        pf = detect_platform(u) or "douyin"
        code = extract_code(pf, u) if pf else None
        existing = find_existing_by_code(pf, code) if (pf and code) else None
        if existing:
            PAGE_TO_PATH[u] = str(existing)  # è®©æŠ½å¸§å¯ç«‹å³ç”¨
            rows.append([u, "", f"âœ… å·²ä¸‹è½½ Â· {existing.name}"])
        else:
            rows.append([u, "", "â³ å¾…è§£æ"])
            to_parse.append(u)
    return rows, to_parse


def _short(u: str, n: int = 28) -> str:
    return (u[:n] + "â€¦") if len(u) > n else u


def build_table(rows: List[Row], step_val: int) -> str:
    """åªè¯» HTML è¡¨æ ¼ï¼›æŠ½å¸§é“¾æ¥ä»…å¯¹å·²ä¸‹è½½å¯ç‚¹"""
    step_val = max(STEP_MIN, min(STEP_MAX, int(step_val or 1)))
    html = [
        "<table style='border-collapse:collapse;width:100%;font-size:14px'>",
        "<thead><tr>",
        "<th style='border:1px solid #ddd;padding:8px'>åºå·</th>",
        "<th style='border:1px solid #ddd;padding:8px'>åŸå§‹é“¾æ¥</th>",
        "<th style='border:1px solid #ddd;padding:8px'>ç›´é“¾é¢„è§ˆ</th>",
        "<th style='border:1px solid #ddd;padding:8px'>çŠ¶æ€</th>",
        f"<th style='border:1px solid #ddd;padding:8px'>æŠ½å¸§ï¼ˆæ¯ {step_val}sï¼‰</th>",
        "</tr></thead><tbody>",
    ]
    for i, (u, direct, status) in enumerate(rows, 1):
        orig = f'<a href="{u}" target="_blank" rel="noopener">åŸå§‹</a>'
        dspan = (
            f'<a href="{direct}" target="_blank" rel="noopener">ç›´é“¾</a>'
            if direct else "<span style='color:#999'>å¾…è§£æ</span>"
        )
        can_extract = (u in PAGE_TO_PATH)
        ex = (
            f'<a href="/api/extract_by_page?page_url={quote(u, safe="")}&step={step_val}" target="_blank">æŠ½å¸§</a>'
            if can_extract else "<span style='color:#999'>è¯·å…ˆä¸‹è½½</span>"
        )
        html.append(
            "<tr>"
            f"<td style='border:1px solid #ddd;padding:8px'>{i}</td>"
            f"<td style='border:1px solid #ddd;padding:8px'>{orig}</td>"
            f"<td style='border:1px solid #ddd;padding:8px;word-break:break-all'>{dspan}</td>"
            f"<td style='border:1px solid #ddd;padding:8px'>{status}</td>"
            f"<td style='border:1px solid #ddd;padding:8px'>{ex}</td>"
            "</tr>"
        )
    html.append("</tbody></table>")
    return "\n".join(html)


# ---------- UI ----------
with gr.Blocks(title="æŠ–éŸ³ç›´é“¾è§£æ + å›ºå®šç›®å½•ä¸‹è½½ + æŠ½å¸§") as demo:
    gr.Markdown("""
# ğŸ¥ æŠ–éŸ³è§†é¢‘ç›´é“¾è§£æ Â· ä¸‹è½½ Â· æŠ½å¸§
- ç‚¹ **ä¸€é”®è§£æ**ï¼šå…ˆåˆ—æ¸…å•ï¼ˆå·²ä¸‹è½½/å¾…è§£æï¼‰ï¼Œ**åªè§£ææœªä¸‹è½½**çš„é“¾æ¥
- å·¦ä¾§å¯**å¤šé€‰**æ¡ç›® â†’ **ä¸‹è½½æ‰€é€‰**ï¼šä»…ä¸‹è½½â€œå°šæœªä¸‹è½½â€çš„ï¼Œ**å·²ä¸‹è½½ä¸é‡å¤**
- å·¦ä¾§å¯**å¤šé€‰**æ¡ç›® â†’ **æŠ½å¸§æ‰€é€‰**ï¼šä»…å¯¹â€œå·²ä¸‹è½½â€çš„æ‰§è¡Œï¼ŒæŒ‰â€œæ¯ N ç§’ä¸€å¸§â€æ‰“åŒ… zip è¿”å›
    """)

    urls_in = gr.Textbox(label="è§†é¢‘é“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", value="\n".join(EXAMPLES), lines=6)
    with gr.Row():
        headless = gr.Checkbox(value=True, label="æ— å¤´æ¨¡å¼ï¼ˆä¸å¼¹çª—ï¼‰")
        wait_ms = gr.Slider(3000, 20000, value=8000, step=500, label="ç­‰å¾…æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰")
    step_slider = gr.Slider(STEP_MIN, STEP_MAX, value=1, step=1, label="æŠ½å¸§é—´éš”ï¼ˆç§’ï¼‰")

    # æ“ä½œæŒ‰é’®
    with gr.Row():
        btn_parse   = gr.Button("ä¸€é”®è§£æ", variant="primary")
        btn_dl      = gr.Button("â¬‡ï¸ ä¸‹è½½æ‰€é€‰ï¼ˆæ‰¹é‡ï¼‰", variant="secondary")
        btn_extract = gr.Button("ğŸ–¼ï¸ æŠ½å¸§æ‰€é€‰ï¼ˆæ‰¹é‡ï¼‰", variant="secondary")

    # å·¦ä¾§å¤šé€‰ + å³ä¾§è¡¨æ ¼
    with gr.Row():
        with gr.Column(scale=1, min_width=300):
            select_multi = gr.CheckboxGroup(choices=[], label="é€‰æ‹©å¤šæ¡ï¼ˆä¸å³ä¾§è¡¨æ ¼åºå·å¯¹åº”ï¼‰", value=[])
            status_note  = gr.Markdown("")
        with gr.Column(scale=5):
            results_html = gr.HTML(label="è§£æç»“æœ")
            extract_msg  = gr.HTML()

    rows_state = gr.State([])  # List[Row]


    # ---------- è§£æï¼ˆä¸¤é˜¶æ®µï¼‰ ----------
    def run_batch(urls_text: str, headless_val: bool, wait_ms_val: int, step_val: int, prog=gr.Progress()):
        global RUNNING
        if RUNNING:
            yield results_html, rows_state, select_multi, status_note
            return
        RUNNING = True
        try:
            urls = [x.strip() for x in urls_text.splitlines() if x.strip()]
            # ç”¨æˆ·è¾“å…¥è¿‡ â†’ è¿‡æ»¤ç¤ºä¾‹
            # if any(u not in EXAMPLES for u in urls):
            #     urls = [u for u in urls if u not in EXAMPLES]
            if not urls:
                yield "<p>è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆé“¾æ¥</p>", [], gr.update(choices=[], value=[]), "âš ï¸ æ— é“¾æ¥"
                return

            # â‘  é¢„æ£€æŸ¥ï¼šç«‹å³å±•ç¤º
            rows_pre, to_parse = precheck_rows(urls)
            table1 = build_table(rows_pre, step_val)
            choices = [f"{i+1}ï½œ{_short(rows_pre[i][0])}" for i in range(len(rows_pre))]
            yield table1, rows_pre, gr.update(choices=choices, value=[]), "æ¸…å•å·²ç”Ÿæˆ"

            # â‘¡ ä»…è§£ææœªä¸‹è½½
            if not to_parse:
                return
            prog(0, desc="è§£ææœªä¸‹è½½çš„è§†é¢‘â€¦")
            parsed = asyncio.run(sniff_serial(to_parse, headless=headless_val, wait_ms=wait_ms_val))
            prog(1)

            dmap = {p: d for (p, d, _s) in parsed}
            smap = {p: s for (p, d, s) in parsed}
            merged: List[Row] = []
            for (u, d, s) in rows_pre:
                if s.startswith("â³"):
                    d = dmap.get(u, "")
                    s = smap.get(u, "âŒ è§£æå¤±è´¥")
                merged.append([u, d, s])

            table2 = build_table(merged, step_val)
            choices2 = [f"{i+1}ï½œ{_short(merged[i][0])}" for i in range(len(merged))]
            yield table2, merged, gr.update(choices=choices2, value=[]), "è§£æå®Œæˆ"
        finally:
            RUNNING = False

    btn_parse.click(
        run_batch,
        inputs=[urls_in, headless, wait_ms, step_slider],
        outputs=[results_html, rows_state, select_multi, status_note],
        show_progress="full"
    )


    # ---------- æ‰¹é‡ä¸‹è½½ ----------
    def do_download(rows: List[Row], selected_list: List[str], step_val: int):
        if not rows:
            return gr.update(), "è¯·å…ˆè§£æ", rows
        if not selected_list:
            return gr.update(), "è¯·å…ˆåœ¨å·¦ä¾§å‹¾é€‰è‡³å°‘ä¸€æ¡", rows

        # è§£æé€‰ä¸­çš„åºå·
        indices: List[int] = []
        for s in selected_list:
            try:
                idx = int(s.split("ï½œ", 1)[0]) - 1
                if 0 <= idx < len(rows):
                    indices.append(idx)
            except Exception:
                pass
        if not indices:
            return gr.update(), "é€‰æ‹©è§£æå¤±è´¥", rows

        # ç»Ÿè®¡å“ªäº›å·²ä¸‹è½½ã€å“ªäº›éœ€è¦ä¸‹è½½
        already, todo = [], []
        for i in indices:
            u, d, st = rows[i]
            if u in PAGE_TO_PATH or (st.startswith("âœ… å·²ä¸‹è½½")):
                already.append(i)
            else:
                todo.append(i)

        if not todo:
            # å…¨éƒ¨å·²ä¸‹è½½
            return build_table(rows, step_val), "æ‰€é€‰è§†é¢‘å…¨éƒ¨å·²ä¸‹è½½ï¼Œæœªé‡å¤ä¸‹è½½ã€‚", rows

        # æ ‡è®°ä¸‹è½½ä¸­
        for i in todo:
            rows[i][2] = "â¬‡ï¸ ä¸‹è½½ä¸­â€¦"
        table_mid = build_table(rows, step_val)

        # é€æ¡ä¸‹è½½ï¼ˆä¸²è¡Œæ›´ç¨³å®šï¼‰
        ok_cnt, fail_cnt = 0, 0
        for i in todo:
            page_url, direct_url, _ = rows[i]
            ok, path, log = download_video(direct_url or None, page_url or None)
            if ok and path:
                PAGE_TO_PATH[page_url] = path
                rows[i][2] = f"âœ… å·²ä¸‹è½½ Â· {Path(path).name}"
                ok_cnt += 1
            else:
                rows[i][2] = "âŒ ä¸‹è½½å¤±è´¥"
                fail_cnt += 1

        tip = f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼šæˆåŠŸ {ok_cnt} æ¡ï¼›å¤±è´¥ {fail_cnt} æ¡ã€‚"
        table_new = build_table(rows, step_val)
        return table_new, tip, rows

    btn_dl.click(
        do_download,
        inputs=[rows_state, select_multi, step_slider],
        outputs=[results_html, status_note, rows_state],
        show_progress="full"
    )


    # ---------- æ‰¹é‡æŠ½å¸§ ----------
    def do_extract(rows: List[Row], selected_list: List[str], step_val: int):
        if not rows:
            return "è¯·å…ˆè§£æ"
        if not selected_list:
            return "è¯·å…ˆåœ¨å·¦ä¾§å‹¾é€‰è‡³å°‘ä¸€æ¡"

        indices: List[int] = []
        for s in selected_list:
            try:
                idx = int(s.split("ï½œ", 1)[0]) - 1
                if 0 <= idx < len(rows):
                    indices.append(idx)
            except Exception:
                pass
        if not indices:
            return "é€‰æ‹©è§£æå¤±è´¥"

        not_downloaded, ok_links, fail_notes = [], [], []
        for i in indices:
            page_url, _, st = rows[i]
            vp = PAGE_TO_PATH.get(page_url)
            if not vp:
                not_downloaded.append(i + 1)  # ç”¨ 1-based åºå·æç¤º
                continue
            ok, zip_path, log = extract_frames(vp, step_val)
            if not ok:
                fail_notes.append(f"ç¬¬{i+1}è¡Œï¼š{log}")
            else:
                href = f"/api/extract_by_page?page_url={quote(page_url, safe='')}&step={step_val}"
                ok_links.append(f"ç¬¬{i+1}è¡Œï¼š<a href='{href}' target='_blank'>ä¸‹è½½zip</a>")

        parts = []
        if ok_links:
            parts.append("âœ… æŠ½å¸§å®Œæˆï¼š<br>" + "<br>".join(ok_links))
        if not_downloaded:
            parts.append("âš ï¸ ä»¥ä¸‹æœªä¸‹è½½ï¼Œå·²è·³è¿‡ï¼š" + "ã€".join(map(str, not_downloaded)))
        if fail_notes:
            parts.append("âŒ å¤±è´¥è¯¦æƒ…ï¼š<br>" + "<br>".join(fail_notes))

        return "<br><br>".join(parts) if parts else "æ²¡æœ‰å¯æŠ½å¸§çš„æ¡ç›®ï¼ˆå¯èƒ½éƒ½æœªä¸‹è½½ï¼‰ã€‚"

    btn_extract.click(
        do_extract,
        inputs=[rows_state, select_multi, step_slider],
        outputs=[extract_msg],
        show_progress="full"
    )


# ---------- FastAPI è·¯ç”±ï¼ˆä¸åç«¯ä¿æŒä¸€è‡´ï¼‰ ----------
app = FastAPI()

@app.get("/api/download")
def api_download(direct_url: str | None = Query(default=None), page_url: str | None = Query(default=None)):
    ok, path, log = download_video(direct_url, page_url)
    return JSONResponse({"status": "ok" if ok else "error", "path": path, "log": log})

@app.get("/api/extract_by_page")
def api_extract_by_page(page_url: str = Query(...), step: int = Query(1)):
    vp = PAGE_TO_PATH.get(page_url)
    if not vp:
        return JSONResponse({"status": "error", "msg": "è¯¥é“¾æ¥å°šæœªåœ¨æœåŠ¡å™¨ä¸‹è½½ï¼Œæ— æ³•æŠ½å¸§ã€‚è¯·å…ˆä¸‹è½½ã€‚"})
    ok, zip_path, log = extract_frames(vp, step)
    if not ok:
        return JSONResponse({"status": "error", "msg": log})
    return FileResponse(zip_path, filename=Path(zip_path).name)

# æŒ‚ Gradio åˆ°æ ¹è·¯å¾„
app = mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=7860)